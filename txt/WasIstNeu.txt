Version 1.1 Beta 6 am 05.12.05
------------------------------

* Neuer Präparator: Mit dem PoiMsPowerPointPreparator steht nun auch ein
  plattformunabhängiger Präparator für Powerpoint zur Verfügung.
  (Vielen Dank an Gerhard Olsson)
* Neuer Präparator: Der IfilterPreparator nutzt die I-Filter-Schnittstelle von
  Microsoft um etliche Dateiformate zu lesen. Leider läuft er nur unter Windows.
* Multiindexsuche: In der SearchConfiguration.xml können nun auch mehrere
  Indizes als Default angegeben werden.
* Die Zusatzfelder (Auxiliary Fields) können nun besser mit Groß-/Kleinschreibung
  umgehen.
* Der vom Crawler an die Webserver gesendete HTTP-Agent ist nun in der
  CrawlerConfiguration.xml konfigurierbar. So kann sich der Crawler
  beispielsweise als Internet Explorer ausgeben.
* Mehrere Bugfixes


Version 1.1 Beta 5 am 13.08.05
------------------------------

* Multiindex-Suche: Es können nun mehrere Suchindizes über eine Suchmaske
  durchsucht werden. Die Suchanfragen werden dabei auf jeden Index losgelassen
  und anschließend vereint.
* In der Weißen und der Schwarzen Liste können jetzt auch reguläre Ausdrücke
  angegeben werden.
* Suchmaske: Der Ort der Ressourcen und der Konfiguration wird jetzt besser
  erkannt, so dass regain auch dann korrekt funktioniert, wenn Tomcat als
  Service läuft.
* Suchmaske: Die File-zu-Http-Brücke ist nun abschaltbar.
* Crawler: Der Crawler braucht nun beim Durchsuchen von Verzeichnissen weniger
  Arbeitsspeicher
* Crawler: Der Crawler nimmt nun auch fehlgeschlagene Dokumente in den Index
  auf, so dass diese bei einem erneuten Durchlauf nicht noch einmal probiert
  werden. Wird der Crawler jedoch mit der Option "-retryFailedDocs" aufgerufen,
  werden alle fehlgeschlagenen erneut probiert.
* Der Html-Präparator übernimmt nun auch die Endungen .jsp, .php, .php3, .php4
  und .asp.
* In der CrawlerConfiguration.xml kann nun bei einem Präparator angegeben
  werden, welche Dokumente er präparieren soll.
* Mehrere Bugfixes


Version 1.1 Beta 4 am 13.04.05
------------------------------

* Zugriffsrechte-Management: Es kann nun ein Rechte-Management eingebunden
  werden, das dafuer sorgt, dass ein Benutzer nur Treffer für Dokumente erhaelt,
  für die er Leserechte hat.
* Suche: Die search-Taglib hat nun ein Tag "hit_field", das ein beliebiges
  Indexfeld ausgibt. Das Tag "hit_summary" wurde in diesem Zuge entfernt.
* Suche: Wenn Sie die Konfiguration der Suche nicht von einer XML-Datei laden
  wollen oder wenn Sie die Lage der XML-Datei nicht in der web.xml angeben
  moechten, koennen Sie die Konfiguration nun ueber eine eigene Factory-Klasse
  erzeugen. Die SearchConfigFactory-Klasse wird in der web.xml festgelegt.
* Serversuche: Die beigelegten JSP-Seiten haben nicht funktioniert.


Version 1.1 Beta 3 am 17.03.05
------------------------------

* Crawler: Bugfix: Der PoiMsExcelPraeparator kam nicht mit allen Zahlen- und
  Datumsformaten klar.
* Crawler: Das Fehler-Log im Index ist nun ausfuehrlicher (Mit Stacktrace).
* Crawler: Die Praeparatoren sind nun in eigene Jars gekapselt. Dadurch ist im
  regain.jar nur das, was regain selbst braucht und die Praeparatoren lassen
  sich leichter austauschen. Ausserdem koennen nun andere Entwickler auch
  Praeparatoren anbieten, die sehr einfach eingebunden werden koennen.
  Die Konfiguration der Praeparatoren steckt weiterhin in der
  CrawlerConfiguration.xml, allerdings muessen dort nicht mehr alle
  Praeparatoren angegeben werden. Die Praeparatoren werden in der Reihenfolge
  abgearbeitet, in der sie konfiguriert sind, die nicht konfigurierten
  Praeparatoren in unbestimmter Reihenfolge danach.
* Desktopsuche: Die Desktopsuche lauft nun auch unter Linux.
* Suche: Bugfix: Dateien, deren URL ein doppelter Slash enthielt
  (Z.B. bei Netzlaufwerken: //fileserver/bla/blubb) konnten nicht geladen werden.
* Desktopsuche: Bugfix: Bei den Suchergebnissen wurden Umlaute falsch
  dargestellt.
* Desktopsuche: In der Statusseite kann nun eine laufende Indexierung angehalten
  und eine Indexierung manuell gestartet werden.
* Crawler: Bugfix: Der HtmlPraeparator kam nicht mit allen Dateien klar.


Version 1.1 Beta 2 am 12.03.05
------------------------------

* Crawler: Der Crawler erstellt nun regelmaeßig sog. Breakpoints. Dabei wird
  der aktuellen Stand der Suchindex in ein gesondertes Verzeichnis kopiert.
  Falls die Indexierung abgebrochen wurde (Z.B. weil der Rechner
  heruntergefahren wurde), wird beim naechsten mal auf dem letzten Breakpoint
  aufgesetzt.
* Desktopsuche: Die Statusseite zeigt nun auch die Zeitmessungsergebnisse.


Version 1.1 Beta 1 am 10.03.05 
------------------------------

* Desktopsuche: regain bietet nun neben der Server-Suche auch eine Desktop-Suche.
  Die Desktop-Suche bietet viele Eigenschaften, die die Bedienung kinderleicht
  machen:
    - Ein Installer fuer Windows.
    - Integration in die Taskleiste unter Linux und Windows.
    - Konfiguration ueber den Browser.
    - Status-Anzeige ueber den Browser.
* Crawler: Es gibt nun einen Praeparator fuer OpenOffice- und StarOffice-Dokumente.
* Gesamt: Aktualisierung auf die neusten Versionen der genutzten Projekte.
* Crawler: Praeparatoren sind nun ueber die CrawlerConfiguration.xml
  konfigurierbar.
* Suche: Die Suche wird nun ueber die SearchConfiguration.xml
  konfiguriert, nicht mehr ueber die web.xml. Dort steht nun nur noch der Pfad
  zur SearchConfiguration.xml.
* Suche: In der Suche kann nun URL-Rewriting eingesetzt werden. Dadurch
  koennen Dokumente von file://c:/www-data/intranet/docs indiziert und im
  Browser als http://intranet.murfman.de/docs angezeigt werden.
* Crawler: Zusatzfelder: Der Index kann durch Zusatzfelder erweitert werden, die
  aus der URL eines Dokuments generiert werden.
  Beispiel: Angenommen Sie haben ein Verzeichnis mit einem Unterverzeichnis fuer
  jedes Projekt. Dann koennten Sie daraus ein Feld mit dem Projektnamen
  generieren. Dadurch bekommen Sie bei der Suche nach "Angebot project:otto23"
  nur Treffer aus diesem Verzeichnis.
* Suche: Expertensuche: Die Werte, die fuer ein Feld im Index stehen,
  koennen nun als ComboBox auf einer Suchseite angeboten werden. Vor allem in
  Verbindung mit Zusatzfeldern ist das sehr praktisch.
* Suche: Weil manche Browser aus Sicherheitsgruenden keine file-Links
  verfolgen, die auf http-Seiten stehen, sind nun alle Dokumente, die sich im
  Index befinden auch ueber HTTP erreichbar. Selbstverstaendlich sind sie bei der
  Desktopsuche nur vom lokalen Rechner aus abrufbar.
* Crawler: Der JacobMsWordPraeparator beruecksichtigt nun Formatvorlagen.
  Dadurch koennen Ueberschriften extrahiert werden, die dann bei der Suche
  staerker gewichtet werden.
* Crawler: Die JacobMsOfficePraeparatoren koennen nun die Beschreibungsfelder
  von MS Office-Dokumenten extrahieren (Titel, Autor, usw.)


Version 1.0 am 10.06.04
-----------------------

* Erste Version

